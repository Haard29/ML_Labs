{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOChNiKQaFxZFe/sPDPG8gR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pWxprPkpMEje","executionInfo":{"status":"ok","timestamp":1677221928218,"user_tz":-330,"elapsed":3426,"user":{"displayName":"CE034_Haard Dholakiya","userId":"10852565062412647382"}},"outputId":"8bedeeda-29ce-4182-e1ff-6313d8e3ca13"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 73.,  67.,  43.],\n","        [ 91.,  88.,  64.],\n","        [ 87., 134.,  58.],\n","        [102.,  43.,  37.],\n","        [ 69.,  96.,  70.]])\n","tensor([[ 56.],\n","        [ 81.],\n","        [119.],\n","        [ 22.],\n","        [103.]])\n","tensor([[ 0.1730],\n","        [-0.8926],\n","        [-0.0290]], requires_grad=True)\n","tensor([0.6993], requires_grad=True)\n","tensor([[ -47.7210],\n","        [ -63.9603],\n","        [-105.5381],\n","        [ -21.1064],\n","        [ -75.0820]], grad_fn=<AddBackward0>)\n","tensor([[ 56.],\n","        [ 81.],\n","        [119.],\n","        [ 22.],\n","        [103.]])\n","tensor(23152.0449, grad_fn=<DivBackward0>)\n","tensor([[ 0.1730],\n","        [-0.8926],\n","        [-0.0290]], requires_grad=True)\n","tensor([[-22792.9355],\n","        [-27497.3438],\n","        [-16328.5371]])\n","tensor([0.6993], requires_grad=True)\n","tensor([-277.7631])\n","tensor([[0.],\n","        [0.],\n","        [0.]])\n","tensor([0.])\n","tensor([[ -47.7210],\n","        [ -63.9603],\n","        [-105.5381],\n","        [ -21.1064],\n","        [ -75.0820]], grad_fn=<AddBackward0>)\n","tensor(23152.0449, grad_fn=<DivBackward0>)\n","tensor([[0.],\n","        [0.],\n","        [0.]])\n","tensor([0.])\n","tensor([[ 0.1730],\n","        [-0.8926],\n","        [-0.0290]], requires_grad=True)\n","tensor([0.6993], requires_grad=True)\n","tensor(23152.0449, grad_fn=<DivBackward0>)\n","tensor(133.5723, grad_fn=<DivBackward0>)\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([[ 56.],\n","        [ 81.],\n","        [119.],\n","        [ 22.],\n","        [103.]])"]},"metadata":{},"execution_count":3}],"source":["import numpy as np\n","import torch\n","\n","# [Temp, Rain, Humidity]\n","inputs = np.array([[73, 67, 43],\n","                   [91, 88, 64],\n","                   [87, 134, 58],\n","                   [102, 43, 37],\n","                   [69, 96, 70]], dtype = 'float32')\n","\n","\n","# [Apples]\n","targets = np.array([[56],\n","                    [81],\n","                    [119],\n","                    [22],\n","                    [103]], dtype='float32')\n","\n","inputs = torch.from_numpy(inputs)\n","targets = torch.from_numpy(targets)\n","\n","print(inputs)\n","print(targets)\n","\n","\n","w = torch.randn(3, 1, requires_grad=True)\n","b = torch.randn(1, requires_grad=True)\n","\n","print(w)\n","print(b)\n","\n","def model(x):\n","    return x @ w + b\n","  \n","preds = model(inputs)\n","print(preds)\n","print(targets)\n","\n","# Loss Function\n","def mse(t1, t2):\n","    diff = t1 - t2\n","    return torch.sum(diff * diff) / diff.numel()\n","\n","loss = mse(preds, targets)\n","print(loss)\n","loss.backward()\n","\n","print(w)\n","print(w.grad)\n","print(b)\n","print(b.grad)\n","\n","w.grad.zero_()\n","b.grad.zero_()\n","\n","print(w.grad)\n","print(b.grad)\n","\n","preds = model(inputs)\n","print(preds)\n","\n","loss = mse(preds, targets)\n","print(loss)\n","\n","print(w.grad)\n","print(b.grad)\n","\n","with torch.no_grad():\n","    w -= w.grad * 1e-5\n","    b -= b.grad * 1e-5\n","    w.grad.zero_()\n","    b.grad.zero_()\n","\n","print(w)\n","print(b)\n","\n","preds = model(inputs)\n","loss = mse(preds, targets)\n","print(loss)\n","\n","for i in range(100):\n","    preds = model(inputs)\n","    loss = mse(preds, targets)\n","    loss.backward()\n","    with torch.no_grad():\n","        w -= w.grad * 1e-5\n","        b -= b.grad * 1e-5\n","        w.grad.zero_()\n","        b.grad.zero_()\n","\n","preds = model(inputs)\n","loss = mse(preds, targets)\n","print(loss)\n","preds\n","targets"]}]}